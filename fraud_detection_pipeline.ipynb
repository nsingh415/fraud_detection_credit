{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ad98af0",
      "metadata": {
        "id": "2ad98af0"
      },
      "source": [
        "# üïµÔ∏è‚Äç‚ôÇÔ∏è Credit Card Fraud Detection - ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9588d7",
      "metadata": {
        "id": "ac9588d7"
      },
      "source": [
        "This notebook demonstrates a complete machine learning pipeline to detect credit card fraud using an imbalanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "metadata": {
        "id": "vzuKEyEnkIMM",
        "outputId": "b3cc01ef-ffab-41e4-c072-6a815ee7bfb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vzuKEyEnkIMM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Collecting imbalanced-learn (from imblearn)\n",
            "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
            "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
            "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f19b194b",
      "metadata": {
        "id": "f19b194b"
      },
      "outputs": [],
      "source": [
        "# üì¶ Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3354e2d6",
      "metadata": {
        "id": "3354e2d6"
      },
      "source": [
        "## üì• Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db796b0",
      "metadata": {
        "id": "5db796b0"
      },
      "outputs": [],
      "source": [
        "# Load dataset (ensure the CSV file is placed in the 'data/' directory)\n",
        "df = pd.read_csv('../data/creditcard.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcf041b6",
      "metadata": {
        "id": "bcf041b6"
      },
      "source": [
        "## üîç Explore and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d5d55c",
      "metadata": {
        "id": "b7d5d55c"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check class distribution\n",
        "print(df['Class'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9372fd28",
      "metadata": {
        "id": "9372fd28"
      },
      "source": [
        "## üìä Handle Imbalanced Dataset using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b01d3a",
      "metadata": {
        "id": "c0b01d3a"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "print(pd.Series(y_resampled).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e89b50",
      "metadata": {
        "id": "d1e89b50"
      },
      "source": [
        "## ü§ñ Train Models and Compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cfa437f",
      "metadata": {
        "id": "7cfa437f"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_preds = lr.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4b93028",
      "metadata": {
        "id": "f4b93028"
      },
      "source": [
        "## üìà Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b8745e0",
      "metadata": {
        "id": "5b8745e0"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(name, y_true, y_pred):\n",
        "    print(f\"\\n{name} Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", y_test, lr_preds)\n",
        "evaluate_model(\"Random Forest\", y_test, rf_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a951b2",
      "metadata": {
        "id": "c9a951b2"
      },
      "source": [
        "## üß™ ROC Curve Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcba0600",
      "metadata": {
        "id": "bcba0600"
      },
      "outputs": [],
      "source": [
        "lr_probs = lr.predict_proba(X_test)[:, 1]\n",
        "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "lr_auc = roc_auc_score(y_test, lr_probs)\n",
        "rf_auc = roc_auc_score(y_test, rf_probs)\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(lr_fpr, lr_tpr, label=f'Logistic Regression (AUC = {lr_auc:.2f})')\n",
        "plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}